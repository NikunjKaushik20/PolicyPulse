# PolicyPulse System Requirements

## 1. Purpose and Scope

PolicyPulse is a semantic retrieval system designed to provide Indian citizens and government service center staff with rapid access to policy information, eligibility criteria, and scheme details across 130+ central and state government programs. The system addresses documented failures in policy discovery, currency of information, and comprehension by providing sub-3-second responses with verifiable sources across 10 Indian languages.

## 2. Stakeholders

**Citizens**
- Rural and urban residents seeking scheme eligibility information
- Farmers, students, elderly, and other demographic groups requiring policy guidance
- Users with varying literacy levels and language preferences

**Government Operators**
- Jan Seva Kendra staff providing frontline citizen services
- Common Service Center operators handling scheme applications
- NGO workers assisting with government program enrollment

**System Administrators**
- Technical staff responsible for data ingestion and system maintenance
- Policy data curators updating scheme information
- Infrastructure operators managing deployment and monitoring

## 3. Functional Requirements

### 3.1 Query Processing

**FR-1:** The system shall accept text queries in natural language and return policy-relevant answers within 3 seconds under normal load conditions.

**FR-2:** The system shall detect policy identifiers from user queries using keyword matching against a predefined alias dictionary containing 50+ policy name variations in English and Hindi.

**FR-3:** The system shall extract year specifications from queries using regex patterns matching 4-digit years, year ranges ("between 2019 and 2021"), and temporal phrases ("from 2015 to 2020").

**FR-4:** The system shall extract demographic information (age, gender, occupation, location type, category) from natural language queries using pattern matching for eligibility determination.

**FR-5:** The system shall perform semantic search against a vector database containing 2,500+ policy document chunks using 384-dimensional embeddings generated by the all-MiniLM-L6-v2 model.

**FR-6:** The system shall return top-5 semantically similar documents with similarity scores, policy identifiers, years, and modality types (budget, news, temporal).

**FR-7:** The system shall synthesize structured answers containing final_answer text, confidence_score (0-1 range), reasoning_steps array, and sources array with policy/year/type metadata.

**FR-8:** The system shall apply time decay weighting to retrieved documents using exponential decay coefficient of 0.1 per year, with minimum weight floor of 0.3 and maximum ceiling of 1.5.

**FR-9:** The system shall increment access_count metadata and boost decay_weight by 0.05 for frequently accessed documents to implement memory reinforcement.

### 3.2 Language Support

**FR-10:** The system shall detect input language automatically using the langdetect library for queries in English, Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, and Punjabi.

**FR-11:** The system shall translate non-English queries to English for embedding generation and vector search operations.

**FR-12:** The system shall translate English-language answers back to the detected input language before returning responses to users.

**FR-13:** The system shall provide a React-based user interface with full localization support for English, Hindi, Tamil, and Telugu including UI labels, placeholders, and quick action buttons.

### 3.3 Eligibility Determination

**FR-14:** The system shall match user demographic profiles against hardcoded eligibility rules for 130+ government schemes covering age, gender, location type, occupation, income, category, and scheme-specific conditions.

**FR-15:** The system shall calculate match percentage for each policy by comparing satisfied rules against total rules and return schemes with match score ≥80%.

**FR-16:** The system shall return eligible schemes with scheme name, benefits description, required documents list, and official application URL.

**FR-17:** The system shall support gender-specific eligibility rules for women-centric schemes including PMMVY and Mahila Samman Savings Certificate.

### 3.4 Policy Change Detection

**FR-18:** The system shall compute semantic drift between consecutive years by calculating cosine distance between year-specific document centroid embeddings.

**FR-19:** The system shall classify drift severity as CRITICAL (>0.70), HIGH (0.45-0.70), MEDIUM (0.25-0.45), or LOW (0.10-0.25) based on distance thresholds.

**FR-20:** The system shall return drift analysis containing year-over-year drift scores, severity classifications, and major change descriptions when temporal queries are detected.

### 3.5 Multimodal Input

**FR-21:** The system shall accept voice input as WAV or MP3 audio files and convert to text using speech recognition with 90% accuracy on clear audio and 79% accuracy with background noise.

**FR-22:** The system shall accept image uploads of identity documents (Aadhaar cards, income certificates) and extract text using pytesseract OCR with 94% accuracy on printed documents and 76% accuracy on income certificates.

**FR-23:** The system shall detect document type (Aadhaar, PAN, ration card) by matching keywords against predefined patterns.

**FR-24:** The system shall extract structured fields (name, document number, date of birth, gender) from OCR text using regex patterns specific to each document type.

**FR-25:** The system shall validate extracted Aadhaar numbers using Verhoeff checksum algorithm and return validation status with extracted fields.

**FR-26:** The system shall generate audio output from text responses using gTTS (Google Text-to-Speech) supporting Indian languages.

### 3.6 Authentication and Session Management

**FR-27:** The system shall support user registration with email and password stored in TinyDB JSON file with bcrypt password hashing.

**FR-28:** The system shall generate JWT access tokens on successful login with configurable expiry time.

**FR-29:** The system shall validate JWT tokens for protected endpoints and return current user information.

**FR-30:** The system shall maintain chat session history per user with session_id, timestamp, query text, and response data stored in TinyDB.

**FR-31:** The system shall retrieve past chat sessions and individual session messages for authenticated users.

### 3.7 Data Coverage

**FR-32:** The system shall provide coverage for 130+ central and state government schemes across 12 categories: Employment & Rural, Financial Inclusion, Agriculture, Health, Education, Infrastructure, Energy & Environment, Urban Development, Skill & Entrepreneurship, Governance & IT, Social Welfare, and Other Schemes.

**FR-33:** The system shall maintain policy data spanning years 2005-2025 with budget allocations, news coverage, and temporal scheme descriptions.

**FR-34:** The system shall store metadata for each document chunk including policy_id, year, modality (budget/news/temporal), source, access_count, and decay_weight.

### 3.8 Error Handling

**FR-35:** The system shall return structured error responses with HTTP status codes and descriptive messages for invalid requests, authentication failures, and processing errors.

**FR-36:** The system shall provide fallback behavior when no exact year matches exist by removing year filters and returning general policy information with a warning flag.

**FR-37:** The system shall log query processing errors, authentication attempts, and system events to policypulse.log file.

### 3.9 External Integrations

**FR-38:** The system shall support WhatsApp integration via Twilio webhook for receiving queries and sending formatted responses with bold text and links.

**FR-39:** The system shall expose ngrok tunnel for Twilio webhook connectivity during development and testing.

## 4. Non-Functional Requirements

### 4.1 Performance

**NFR-1:** The system shall process simple text queries in ≤180ms on Intel i5 CPU with 8GB RAM and SSD storage.

**NFR-2:** The system shall complete drift analysis queries in ≤800ms under normal load.

**NFR-3:** The system shall add ≤300ms latency for translation operations and ≤500ms for text-to-speech generation.

**NFR-4:** The system shall support approximately 10 queries per second with current single-process ChromaDB configuration.

**NFR-5:** The system shall handle approximately 50 concurrent users before performance degradation.

**NFR-6:** The system shall maintain acceptable performance with up to 10,000 document chunks before requiring optimization.

### 4.2 Accuracy

**NFR-7:** The system shall achieve 78% overall accuracy for year and modality correctness on test queries.

**NFR-8:** The system shall achieve 92% year accuracy for year-specific queries (correct year in top-1 result).

**NFR-9:** The system shall achieve 85% modality accuracy when modality is explicitly expected in query.

**NFR-10:** The system shall maintain average top-1 similarity score of 0.62 for semantic search results.

**NFR-11:** The system shall achieve Hit@5 rate of 0.92 (relevant result in top-5) and Mean Reciprocal Rank of 0.81.

**NFR-12:** The system shall achieve 80% precision on CRITICAL drift threshold (>0.70) for detecting major policy changes.

### 4.3 Reliability

**NFR-13:** The system shall provide deterministic responses where identical queries return identical answers for reproducibility and auditability.

**NFR-14:** The system shall persist vector database to disk in ./chromadb_data directory to survive process restarts.

**NFR-15:** The system shall persist user data and chat history to policypulse_db.json file with atomic write operations.

### 4.4 Usability

**NFR-16:** The system shall provide a responsive React-based web interface supporting desktop and mobile browsers.

**NFR-17:** The system shall support light and dark theme modes with user preference persistence.

**NFR-18:** The system shall display confidence scores and source citations for all generated answers to enable user verification.

**NFR-19:** The system shall provide quick action buttons for common query patterns (scheme suggestions, budget queries, eligibility checks).

**NFR-20:** The system shall complete full setup including data ingestion in 3-5 minutes using automated setup scripts.

### 4.5 Security

**NFR-21:** The system shall hash passwords using bcrypt with salt before storage.

**NFR-22:** The system shall validate all API inputs using Pydantic models to prevent injection attacks.

**NFR-23:** The system shall configure CORS headers (currently permissive for demonstration purposes).

**NFR-24:** The system shall not store Aadhaar numbers or other personally identifiable information extracted from uploaded documents beyond the current session.

### 4.6 Resource Constraints

**NFR-25:** The system shall operate on minimum 4GB RAM (8GB recommended) with 2GB disk space for dependencies and data.

**NFR-26:** The system shall load embedding model (all-MiniLM-L6-v2) requiring approximately 400MB memory.

**NFR-27:** The system shall store ChromaDB vector database requiring approximately 50MB disk space for 2,500+ chunks.

**NFR-28:** The system shall operate entirely offline after initial setup except for optional translation and TTS features.

## 5. Constraints and Assumptions

### 5.1 Technical Constraints

**C-1:** The system uses ChromaDB file-based storage limiting deployment to single-process, single-machine configuration.

**C-2:** The system uses TinyDB JSON file storage limiting concurrent write operations and scalability beyond 100 users.

**C-3:** The system uses CPU-based embedding generation (all-MiniLM-L6-v2) without GPU acceleration.

**C-4:** The system uses template-based answer synthesis rather than LLM generation to ensure reproducibility and eliminate hallucination risk.

**C-5:** The system supports single-policy queries only; multi-policy comparison queries are not implemented due to ChromaDB filter limitations.

### 5.2 Data Constraints

**C-6:** Policy data is ingested once at setup time; the system does not perform real-time scraping of government websites.

**C-7:** Data currency depends on manual updates to CSV files in Data/ directory by system administrators.

**C-8:** Ground truth for evaluation was created by development team without independent domain expert validation.

**C-9:** Test set contains 64 queries across 130+ policies, representing limited coverage of possible query patterns.

### 5.3 Operational Assumptions

**A-1:** The system assumes deployment behind reverse proxy handling HTTPS termination.

**A-2:** The system assumes internet connectivity for optional translation (deep-translator) and TTS (gTTS) features.

**A-3:** The system assumes Tesseract OCR engine installed separately for document processing features.

**A-4:** The system assumes current year is 2026 for time decay calculations.

**A-5:** The system assumes users have basic literacy to interact with text or voice interface.

### 5.4 Integration Constraints

**C-10:** WhatsApp integration requires Twilio Sandbox configuration; direct SMS delivery requires A2P 10DLC registration (3-week process).

**C-11:** Translation quality depends on deep-translator library wrapping Google Translate free tier with 500K character monthly limit.

**C-12:** OCR accuracy on handwritten documents is 56%, limiting practical use to printed documents only.

## 6. Out-of-Scope Items

**OS-1:** LLM-based answer generation (system uses retrieval + template synthesis only)

**OS-2:** Real-time policy scraping from government websites (data ingested manually)

**OS-3:** Application submission and enrollment flows (system provides information and links only)

**OS-4:** USSD interface for feature phones (requires direct telecom integration)

**OS-5:** Direct SMS delivery to Indian phone numbers (backend implemented but requires A2P 10DLC registration)

**OS-6:** Multi-policy comparison queries (e.g., "Compare NREGA and PM-KISAN eligibility")

**OS-7:** Disability-specific eligibility rules (not present in current rule set)

**OS-8:** Caste certificate OCR processing (tested at <60% accuracy, excluded)

**OS-9:** Rate limiting and audit logging (slowapi imported but not configured)

**OS-10:** Aadhaar-based authentication (system uses email/password only)

**OS-11:** Production-grade scalability (distributed vector store, PostgreSQL, Redis caching)

**OS-12:** Automated policy change notifications (drift detection is query-triggered only)

**OS-13:** User feedback collection and answer quality improvement loops

**OS-14:** Integration with government enrollment systems (e.g., UMANG, DigiLocker)

**OS-15:** Support for regional language documents beyond Hindi, Tamil, Telugu in OCR
